{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif: filter questions tokens using pretrained morpho-Syntactic Tagger (POS)\n",
    "---\n",
    "turn questions into keywords:\n",
    "ex: Qui est le président de la France ? --> président France\n",
    "\n",
    "Two pos tagger tested:\n",
    "* [spaCy](#SpaCy)\n",
    "* [Stanford NLP](#Stanford-Postagger)\n",
    "* [Tests](#Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ADJ\n",
      "cherche NOUN\n",
      "a AUX\n",
      "acheter VERB\n",
      "une DET\n",
      "startup ADJ\n",
      "anglaise NOUN\n",
      "pour ADP\n",
      "1 NUM\n",
      "milliard NOUN\n",
      "de ADP\n",
      "dollard NOUN\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.fr.examples import sentences\n",
    "\n",
    "doc = loader(sentences[0])\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://spacy.io/api/annotation\n",
    "\n",
    "spacy_filter_hard = [\"NOUN\",\"PROPN\", \"VERB\", \"X\"]\n",
    "spacy_filter_soft = [\"NOUN\",\"PROPN\", \"VERB\", \"X\",\"ADJ\", \"ADV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_sent_spacy(sent, filt):\n",
    "    doc = loader(sent)\n",
    "    return \" \".join([tok.text for tok in doc if tok.pos_ in filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_filter(sentence, func, filt):\n",
    "    print(\"keywords: \", func(sentence, filt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  Apple cherche a acheter une startup anglaise pour 1 milliard de dollard\n",
      "keywords:  cherche acheter anglaise milliard dollard\n"
     ]
    }
   ],
   "source": [
    "test_filter(sentences[0], filter_sent_spacy, spacy_filter_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Postagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/armand/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8' )\n",
    "res = pos_tagger.tag('je suis libre'.split())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://ftb.linguist.univ-paris-diderot.fr/fichiers/public/guide-constit.pdf\n",
    "stan_filter_hard = [\"N\", \"V\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def filter_sent_stanford(sent, filt):\n",
    "    sent = word_tokenize(sent)\n",
    "    tags = pos_tagger.tag(sent)\n",
    "    return \" \".join([w for w, t in tags if t[:1] in filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche a acheter startup milliard dollard'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_sent_stanford(sentences[0], stan_filter_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  Apple cherche a acheter une startup anglaise pour 1 milliard de dollard\n",
      "keywords:  Apple cherche a acheter startup milliard dollard\n"
     ]
    }
   ],
   "source": [
    "test_filter(sentences[0], filter_sent_stanford, stan_filter_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_both(sent):\n",
    "    print(\"--\"*12,\"testing\" ,\"--\"*12)\n",
    "    print(\"Original:\", sent)\n",
    "    print(\"STANFORD:\")\n",
    "    test_filter(sent, filter_sent_stanford, stan_filter_hard)\n",
    "    print(\"SPACY:\")\n",
    "    test_filter(sent, filter_sent_spacy, spacy_filter_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ testing ------------------------\n",
      "Original: Apple cherche a acheter une startup anglaise pour 1 milliard de dollard\n",
      "STANFORD:\n",
      "keywords:  Apple cherche a acheter startup milliard dollard\n",
      "SPACY:\n",
      "keywords:  cherche acheter anglaise milliard dollard\n",
      "------------------------ testing ------------------------\n",
      "Original: Les voitures autonomes voient leur assurances décalées vers les constructeurs\n",
      "STANFORD:\n",
      "keywords:  voitures voient assurances décalées constructeurs\n",
      "SPACY:\n",
      "keywords:  voitures voient assurances décalées constructeurs\n",
      "------------------------ testing ------------------------\n",
      "Original: San Francisco envisage d'interdire les robots coursiers\n",
      "STANFORD:\n",
      "keywords:  envisage d'interdire\n",
      "SPACY:\n",
      "keywords:  San Francisco envisage interdire robots\n",
      "------------------------ testing ------------------------\n",
      "Original: Londres est une grande ville du Royaume-Uni\n",
      "STANFORD:\n",
      "keywords:  Londres est ville Royaume-Uni\n",
      "SPACY:\n",
      "keywords:  Londres ville Royaume-Uni\n",
      "------------------------ testing ------------------------\n",
      "Original: L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe\n",
      "STANFORD:\n",
      "keywords:  L Italie choisit ArcelorMittal reprendre aciérie\n",
      "SPACY:\n",
      "keywords:  Italie choisit ArcelorMittal reprendre aciérie d’ Europe\n",
      "------------------------ testing ------------------------\n",
      "Original: Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon\n",
      "STANFORD:\n",
      "keywords:  Apple lance HomePod sent menacé l'Echo d'Amazon\n",
      "SPACY:\n",
      "keywords:  lance menacé Echo Amazon\n",
      "------------------------ testing ------------------------\n",
      "Original: La France ne devrait pas manquer d'électricité cet été, même en cas de canicule\n",
      "STANFORD:\n",
      "keywords:  France devrait manquer d'électricité été cas canicule\n",
      "SPACY:\n",
      "keywords:  France devrait manquer électricité été cas canicule\n",
      "------------------------ testing ------------------------\n",
      "Original: Nouvelles attaques de Trump contre le maire de Londres\n",
      "STANFORD:\n",
      "keywords:  attaques Trump maire Londres\n",
      "SPACY:\n",
      "keywords:  attaques Trump maire Londres\n",
      "------------------------ testing ------------------------\n",
      "Original: Où es-tu ?\n",
      "STANFORD:\n",
      "keywords:  \n",
      "SPACY:\n",
      "keywords:  es tu\n",
      "------------------------ testing ------------------------\n",
      "Original: Qui est le président de la France ?\n",
      "STANFORD:\n",
      "keywords:  est président France\n",
      "SPACY:\n",
      "keywords:  président France\n",
      "------------------------ testing ------------------------\n",
      "Original: Où est la capitale des Etats-Unis ?\n",
      "STANFORD:\n",
      "keywords:  est capitale Etats-Unis\n",
      "SPACY:\n",
      "keywords:  capitale Etats-Unis\n",
      "------------------------ testing ------------------------\n",
      "Original: Quand est né Barack Obama ?\n",
      "STANFORD:\n",
      "keywords:  est né Barack Obama\n",
      "SPACY:\n",
      "keywords:  né Barack Obama\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_both(i) for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
